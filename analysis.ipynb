{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "from emoji import UNICODE_EMOJI\n",
    "from IPython.core.display import display, HTML\n",
    "from tweepy import OAuthHandler, Stream, StreamListener, API as TwApi\n",
    "\n",
    "from util.misc import SKIN_TONES, STATE_LOOKUP, STATES\n",
    "from util.tfidf import tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.environ.get('TW_CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.environ.get('TW_CONSUMER_SECRET')\n",
    "ACCESS_TOKEN_KEY = os.environ.get('TW_ACCESS_TOKEN_KEY')\n",
    "ACCESS_TOKEN_SECRET = os.environ.get('TW_ACCESS_TOKEN_SECRET')\n",
    "\n",
    "DATA_DIR = 'data2'\n",
    "USA_BBOX = [-175.1, 22.4, -59.8, 72.3]  # via http://boundingbox.klokantech.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a few helper functions\n",
    "\n",
    "def extract_emojis(txt):\n",
    "    return [c for c in txt if c in UNICODE_EMOJI]\n",
    "\n",
    "def sort_values(data):\n",
    "    return sorted(data.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def get_json(fname):\n",
    "    with open('{}/{}'.format(DATA_DIR, fname)) as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_to_json(data, fname):\n",
    "    with open('{}/{}'.format(DATA_DIR, fname), 'w') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 1: fetch tweets (within USA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this uses Twitter's streaming API\n",
    "# for demo purposes, this only fetches 1k tweets\n",
    "# (in reality, this ran over several days and collected millions of tweets)\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ct = 0\n",
    "        self.started = time()\n",
    "\n",
    "    def on_status(self, data):\n",
    "        if hasattr(data, 'retweeted_status'):\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open('{}/tweets.json'.format(DATA_DIR), 'a') as f:\n",
    "                f.write('{}\\n'.format(json.dumps(data._json)))\n",
    "        except Exception as e:\n",
    "            print('error: {}'.format(str(e)))\n",
    "\n",
    "        self.ct += 1\n",
    "        if (self.ct % 100 == 0):\n",
    "            print('ðŸš¨ {} tweets... ({} secs elapsed)'.format(\n",
    "                self.ct,\n",
    "                int((time() - self.started))\n",
    "            ))\n",
    "\n",
    "        if self.ct > 1000:\n",
    "            return False\n",
    "            \n",
    "    def on_error(self, status):\n",
    "        print('uh-oh! ({})'.format(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ 100 tweets... (4 secs elapsed)\n",
      "ðŸš¨ 200 tweets... (8 secs elapsed)\n",
      "ðŸš¨ 300 tweets... (13 secs elapsed)\n",
      "ðŸš¨ 400 tweets... (17 secs elapsed)\n",
      "ðŸš¨ 500 tweets... (21 secs elapsed)\n",
      "ðŸš¨ 600 tweets... (26 secs elapsed)\n",
      "ðŸš¨ 700 tweets... (29 secs elapsed)\n",
      "ðŸš¨ 800 tweets... (34 secs elapsed)\n",
      "ðŸš¨ 900 tweets... (38 secs elapsed)\n",
      "ðŸš¨ 1000 tweets... (42 secs elapsed)\n"
     ]
    }
   ],
   "source": [
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n",
    "api = TwApi(auth)\n",
    "\n",
    "stream = Stream(auth, MyListener())\n",
    "stream.filter(locations=USA_BBOX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 2: filter tweets to ones containing emojis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with 0...\n",
      "770 tweets with emojis\n"
     ]
    }
   ],
   "source": [
    "filtered = []\n",
    "\n",
    "with open('{}/tweets.json'.format(DATA_DIR)) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        d = json.loads(line)\n",
    "        emojis = extract_emojis(d['text'])\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print('done with {}...'.format(i))\n",
    "\n",
    "        if not len(emojis):\n",
    "            continue\n",
    "\n",
    "        filtered.append({\n",
    "            'id': d['id_str'],\n",
    "            'time': d['created_at'],\n",
    "            'user': d['user']['screen_name'],\n",
    "            'text': d['text'],\n",
    "            'coordinates': d['coordinates'],\n",
    "            'place': d['place'],\n",
    "            'emojis': emojis,\n",
    "            'emojis_names': [UNICODE_EMOJI[e] for e in emojis],\n",
    "        })\n",
    "\n",
    "print('{} tweets with emojis'.format(len(filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_json(filtered, 'tweets-w-emojis.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 3: aggregate by emoji and state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coordinates': None,\n",
       " 'emojis': ['ðŸ’˜'],\n",
       " 'emojis_names': [':heart_with_arrow:'],\n",
       " 'id': '872474708570144769',\n",
       " 'place': {'attributes': {},\n",
       "  'bounding_box': {'coordinates': [[[-75.503507, 43.170051],\n",
       "     [-75.503507, 43.279981],\n",
       "     [-75.382773, 43.279981],\n",
       "     [-75.382773, 43.170051]]],\n",
       "   'type': 'Polygon'},\n",
       "  'country': 'United States',\n",
       "  'country_code': 'US',\n",
       "  'full_name': 'Rome, NY',\n",
       "  'id': '00228ed265b1139e',\n",
       "  'name': 'Rome',\n",
       "  'place_type': 'city',\n",
       "  'url': 'https://api.twitter.com/1.1/geo/id/00228ed265b1139e.json'},\n",
       " 'text': 'I loved it AGAIN ðŸ’˜thanks to grandma. https://t.co/2c3e4ARSMI',\n",
       " 'time': 'Wed Jun 07 15:25:54 +0000 2017',\n",
       " 'user': 'chas_x0'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_json('tweets-w-emojis.json')\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_cts, emoji_cts = defaultdict(int), defaultdict(int)\n",
    "state_emoji_cts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for d in data:\n",
    "    place = d['place']\n",
    "\n",
    "    if not place:\n",
    "        continue\n",
    "\n",
    "    country, ptype = place['country_code'], place['place_type']\n",
    "    if country != 'US' or ptype not in ['city', 'admin']:\n",
    "        continue\n",
    "\n",
    "    state = place['name']\n",
    "    if ptype == 'city':\n",
    "        state = STATE_LOOKUP[place['full_name'][-2:].upper()]\n",
    "\n",
    "    if state not in STATES:\n",
    "        continue\n",
    "\n",
    "    state_cts[state] += 1\n",
    "    for e in d['emojis_names']:\n",
    "        if e not in SKIN_TONES:\n",
    "            emoji_cts[e] += 1\n",
    "            state_emoji_cts[state][e] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Texas', 94),\n",
       " ('California', 90),\n",
       " ('Florida', 59),\n",
       " ('Ohio', 44),\n",
       " ('New York', 38),\n",
       " ('Georgia', 33),\n",
       " ('Virginia', 25),\n",
       " ('Louisiana', 23),\n",
       " ('Pennsylvania', 22),\n",
       " ('Tennessee', 19)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_values(state_cts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(':face_with_tears_of_joy:', 274),\n",
       " (':red_heart:', 65),\n",
       " (':loudly_crying_face:', 63),\n",
       " (':smiling_face_with_heart-eyes:', 57),\n",
       " (':face_with_rolling_eyes:', 36),\n",
       " (':weary_face:', 35),\n",
       " (':raising_hands:', 32),\n",
       " (':fire:', 31),\n",
       " (':female_sign:', 29),\n",
       " (':smiling_face_with_smiling_eyes:', 29)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_values(emoji_cts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama:\n",
      "[(':hundred_points:', 4), (':face_with_tears_of_joy:', 4), (':red_heart:', 2)]\n",
      "Alaska:\n",
      "[(':crying_face:', 1), (':sneezing_face:', 1), (':sparkling_heart:', 1)]\n",
      "Arizona:\n",
      "[(':thumbs_up:', 4), (':down_button:', 4), (':heavy_check_mark:', 3)]\n",
      "Arkansas:\n",
      "[(':face_with_tears_of_joy:', 2), (':raising_hands:', 2), (':person_facepalming:', 1)]\n",
      "California:\n",
      "[(':white_heavy_check_mark:', 21), (':face_with_tears_of_joy:', 20), (':white_medium_star:', 20)]\n"
     ]
    }
   ],
   "source": [
    "# show most popular emojis by state \n",
    "\n",
    "results = []\n",
    "\n",
    "for state, emojis in sorted(state_emoji_cts.items()):\n",
    "    results.append({\n",
    "        'state': state,\n",
    "        'emojis': dict(emojis),\n",
    "        'top_emojis': sort_values(emojis)[:10],\n",
    "    })\n",
    "\n",
    "for r in results[:5]:\n",
    "    print('{}:\\n{}'.format(r['state'], r['top_emojis'][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_json(results, 'emojis-by-state.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 4: add tf-idf (term frequencyâ€“inverse document frequency)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = get_json('emojis-by-state.json')\n",
    "counts_list = [d['emojis'] for d in data]\n",
    "\n",
    "data_w_tfidf = []\n",
    "\n",
    "for d in data:    \n",
    "    counts = d['emojis']\n",
    "    scores = {word: tfidf(word, counts, counts_list) for word in counts}\n",
    "    sorted_words = sort_values(scores)\n",
    "\n",
    "    data_w_tfidf.append({\n",
    "        'state': d['state'],\n",
    "        'top_emojis': d['top_emojis'],\n",
    "        'tfidf': sorted_words[:10],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama:\n",
      "\t1. :airplane: tf-idf: 0.23226\n",
      "\t2. :hundred_points: tf-idf: 0.21196\n",
      "\t3. :angry_face: tf-idf: 0.10111\n",
      "Alaska:\n",
      "\t1. :sneezing_face: tf-idf: 0.6271\n",
      "\t2. :crying_face: tf-idf: 0.54601\n",
      "\t3. :sparkling_heart: tf-idf: 0.40738\n",
      "Arizona:\n",
      "\t1. :down_button: tf-idf: 0.40458\n",
      "\t2. :heavy_check_mark: tf-idf: 0.30343\n",
      "\t3. :thumbs_up: tf-idf: 0.21051\n",
      "Arkansas:\n",
      "\t1. :smirking_face: tf-idf: 0.24818\n",
      "\t2. :rolling_on_the_floor_laughing: tf-idf: 0.18517\n",
      "\t3. :raising_hands: tf-idf: 0.17059\n",
      "California:\n",
      "\t1. :white_heavy_check_mark: tf-idf: 0.27563\n",
      "\t2. :white_medium_star: tf-idf: 0.2625\n",
      "\t3. :smiling_face_with_smiling_eyes: tf-idf: 0.07291\n"
     ]
    }
   ],
   "source": [
    "# preview results\n",
    "\n",
    "for d in data_w_tfidf[:5]:\n",
    "    print('{}:'.format(d['state']))\n",
    "\n",
    "    for i, result in enumerate(d['tfidf'][:3]):\n",
    "        word, score = result\n",
    "        print(\"\\t{}. {} tf-idf: {}\".format(i + 1, word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_json(data_w_tfidf, 'emojis-by-state-more.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
